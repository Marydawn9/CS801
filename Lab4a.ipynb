{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> CS801 - Lab 4a (2020) </div>\n",
    "\n",
    "# Simple application of Bayes Law\n",
    "\n",
    "As usual, follow those parts of the lab that have been set up - sometimes involving aspects of Python that you may not yet be familiar with, but try to make sure you get a feel for what is happening in terms of probability and Bayes...  There are various 'exercises' which are the elements that should form part if this week's submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Part 1: Using Bayes to understand medical diagnosis\n",
    "\n",
    "Depending on how familiar you are with the terms from medical diagnosis you may need to refer to the formulae in mini-lecture 4.2 to translate the example below into a function that uses Bayes Law to properly interpret the results from diagnostic tests.\n",
    "\n",
    "## Exercise 1a (SUBMIT)\n",
    "Build a function in Python that takes in the following three parameters:\n",
    "- the prevalence of some disease in a population (sometimes called the 'base rate')\n",
    "- the sensitivity of a diagnostic test (also referred to as the 'true positive rate')\n",
    "- the specificity of a diagnostic test (also referred to as the 'true negative rate')\n",
    "\n",
    "<br> and returns a value that represents the probability that a patient from that population has the disease based on getting a positive result from such a test.\n",
    "\n",
    "<br>\n",
    "Start with the example from the mini-lecture:\n",
    "- prevalence of some rare disease = 1 in 5,000\n",
    "- sensitivity = 99%\n",
    "- specificity = 95%\n",
    "\n",
    "<br>\n",
    "Given these parameters your function should return a value of **0.4%**, - i.e. the P(disease | +test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(D|T+) = P(D) X P(T+|D)/ P(T+)\n",
    "\n",
    "def bayeslaw(p_d, p_tpositive_given_d, notspecificity_):\n",
    "    prior = p_d #0.99\n",
    "    likelihood = p_tpositive_given_d #0.0002\n",
    "    notlikelihood = 1 - likelihood \n",
    "    marginalization = (prior * likelihood) + (notspecificity_ * notlikelihood)\n",
    "    pd_given_tpositive = (p_d * likelihood) / marginalization \n",
    "    return pd_given_tpositive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(disease|+test) = 0.395%\n"
     ]
    }
   ],
   "source": [
    "p_d = 0.99\n",
    "p_tpositive_given_d = 0.0002 \n",
    "notspecificity_ = 0.05\n",
    "result = bayeslaw(p_d, p_tpositive_given_d, notspecificity_)\n",
    "\n",
    "print('P(disease|+test) = %.3f%%' % (result * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 1b (SUBMIT)\n",
    "How (if at all) does your belief that this patient has the disease alter if she gets a **second** positive test? (Assume this has the same 'test characteristics' but is run by a different lab, just to that we know the two tests are in some way independent.) Does that makes sense to you?\n",
    "\n",
    "\n",
    "\n",
    "## Exercise 1c (SUBMIT)\n",
    "What about if the level of specificity is equal to the sensitivity - i.e. both are at 99%.  How does this alter things? (On both the first and subsequent runs of this 'new improved' test.) How have these exercises impacted on your understanding of how 'sensitivity' and 'specificity' in diagnositc tests should be understood?\n",
    "\n",
    "\n",
    "\n",
    "## Exercise 1d (SUBMIT)\n",
    "Try some other scenarios, e.g.:\n",
    "- look at a much more common disease (you may need to check the Web for base rates of some common disease outcomes)\n",
    "- check how the values change on the case where you have a much less 'good' test:\n",
    "    - e.g. one that gives a false positive result in around 15% of cases\n",
    "    - or, a diagnostic test that provides a negative result for 10% of patients who actually have the disease\n",
    "\n",
    "<br> Which of the parameters seems to have the largest impact on the outcome (i.e. your belief that there really is something that you should be worried about)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(disease|+test) = 92.958%\n"
     ]
    }
   ],
   "source": [
    "#1B \n",
    "\n",
    "p_d = 0.99\n",
    "p_tpositive_given_d = 0.4 #changed this to 0.4% based on previous test taken\n",
    "notspecificity_ = 0.05\n",
    "result = bayeslaw(p_d, p_tpositive_given_d, notspecificity_)\n",
    "\n",
    "print('P(disease|+test) = %.3f%%' % (result * 100))\n",
    "\n",
    "#belief is altered that this patient most likely has the disease as there is now another test used as a basis\n",
    "#strengthening our p_d(prior belief) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(disease|+test) = 1.942%\n"
     ]
    }
   ],
   "source": [
    "#1Ca\n",
    "p_d = 0.99 #changed sensitivity \n",
    "p_tpositive_given_d = 0.0002 #using initial positivity rate \n",
    "notspecificity_ = 0.01 #with specificity as 99%\n",
    "result = bayeslaw(p_d, p_tpositive_given_d, notspecificity_)\n",
    "\n",
    "print('P(disease|+test) = %.3f%%' % (result * 100))\n",
    "\n",
    "#the sensitivity of a diagnostic test (also referred to as the 'true positive rate')\n",
    "#the specificity of a diagnostic test (also referred to as the 'true negative rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(disease|+test) = 98.507%\n"
     ]
    }
   ],
   "source": [
    "#1Cb\n",
    "p_d = 0.99 #changed sensitivity \n",
    "p_tpositive_given_d = 0.4 #using positivity rate after second test was taken \n",
    "notspecificity_ = 0.01 #with specificity as 99%\n",
    "result = bayeslaw(p_d, p_tpositive_given_d, notspecificity_)\n",
    "\n",
    "print('P(disease|+test) = %.3f%%' % (result * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(disease|+test) = 54.902%\n"
     ]
    }
   ],
   "source": [
    "#1Da\n",
    "#using common disease rate of flu in US \n",
    "#prevalence = 8% \n",
    "#sensitivity = 70%  probability that the symptom is present given that the person has a disease\n",
    "#specificity = 95% probability that the symptom is not present given that the person does not have a disease\n",
    "p_d = 0.70\n",
    "p_tpositive_given_d = 0.08\n",
    "notspecificity_ = 0.05\n",
    "result = bayeslaw(p_d, p_tpositive_given_d, notspecificity_)\n",
    "\n",
    "print('P(disease|+test) = %.3f%%' % (result * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Part 2: M&Ms and Bayes\n",
    "\n",
    "So-called 'urn' (or 'bag') problems don't always present in the *classic* manner we came across last week - dating back to Bernoulli. The problem below is in the same basic format as the 'urn' problems of last week but allow for a little bit of a twist. This example is based on an example around the American candy, M&Ms and their production over time, and is based on an entry from [Allen Downey's](https://www.allendowney.com/blog/) excellent blog (though as always, any errors introduced in editing are entirely my fault!)\n",
    "\n",
    "> The blue M&M was introduced in 1995.  Before then, the colour mix in a bag of M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  After 1995 it was (24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown).\n",
    "\n",
    "> A friend of mine has two bags of M&Ms, and he tells me that one is from 1994 and one from 1996 but won't tell me which is which. He gives me a yellow M&M, what is the probability that this came from the 1994 bag?\n",
    "\n",
    "Now that you have picked up on the basic ideas of Bayesian reasoning you should see that this seems to be a good candidate, in that we are asked to estimate the probability of a hypothesis (that the yellow M&M is from 1994) given some evidence. It is not immediately obvivous how we might do this but we should be able to take the probabilities that we have been given and work in the 'opposite' direction, i.e. what is the probability that we would have recieved this 'evidence' under the different hypotheses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You may feel that all this reasoning is 'over-kill', but we are going to add a bit more evidence in a moment, so breaking down our thinking in this way will ultimately pay off...\n",
    "\n",
    "Before we see the colour of the M&M, there are two hypotheses, `A` and `B`, both with equal probability:\n",
    "\n",
    "    A: the M&M was from the 94 bag\n",
    "    B: the M&M was from 96 bag\n",
    "    P(A) = P(B) = 0.5\n",
    "    \n",
    "Then we get some evidence:\n",
    "    \n",
    "    E: the M&M is yellow\n",
    "    \n",
    "We want to know the probability of hypothesis `A`, given the evidence:\n",
    "    \n",
    "    P(A | E)\n",
    "    \n",
    "We *could* enumerate the sample space to estimate this but that will start to become more tricky as we are given more evidence (see below). So instead let's take what we know from Bayes' Theorem, namely that:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E)\n",
    "    \n",
    "The quantities on the right-hand-side of this equation are all pretty straight-forward to calculate:\n",
    "    \n",
    "    P(E | A) = 0.20\n",
    "    P(E | B) = 0.14\n",
    "    P(A)     = 0.5\n",
    "    P(B)     = 0.5\n",
    "    P(E)     = P(E | A) * P(A) + P(E | B) * P(B) \n",
    "             = 0.20     * 0.5  + 0.14     * 0.5   =   0.17\n",
    "    \n",
    "We can use Bayes Law to get a final answer:\n",
    "   \n",
    "    P(A | E) = P(E | A) * P(A) / P(E) \n",
    "             = 0.20     * 0.5  / 0.17 \n",
    "             = 0.588\n",
    "\n",
    "i.e. There is about a 59% chance that this yellow M&M was taken was the 1994 bag.  \n",
    "\n",
    "You may say, \"well that was a LOT of work to calcuate what was a lot more obvious, by simply noting that 20/34 (i.e. 1994_yellows / all_yellows) is the proportion / likelihood of the yellow come from the 1994 bag\". And you would be correct, but see whether your mind might change when faced with the next question...  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 2a (SUBMIT)\n",
    "\n",
    "Let's think about a slightly more 'interesting' situation...  Say this time that our friend draws one M&M from each bag - the first one is yellow and the seceond one is green. Now how might you go about estimating the probability that the yellow M&M came from the 1994 bag?\n",
    "\n",
    "<br>\n",
    "You should be able to use the approach outlined above to estimate this value. It might be useful to build some little 'Bayes estimator' helper function in Python to allow you to explore this and then other selections of M&Ms. Depending on how comfortbale you feel with Python you might try this rather than (or in addition to) working out each option *by hand* (as we did above).\n",
    "\n",
    "<br>\n",
    "(I estimated that there was now a 74% chance that the yellow M&M came from the 1994 bag... Did you find the same?  Does this value make sense to you?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algebra showing how values were gotten for yellow and green m&m\n",
    "\n",
    "A = Bag 1(1994) and Bag 2(1996)\n",
    "\n",
    "B = Bag 1(1996) and Bag 2(1994) \n",
    "\n",
    "P(A) = P(B) = 0.50 \n",
    "\n",
    "Knowledge = Yellow m&m from Bag 1 and green m&m from Bag 2 \n",
    "\n",
    "P(E|A) = Yellow 1994, Green 1996 = $ 0.2 * 0.2  = 0.4 $\n",
    "\n",
    "P(E|B) = Yellow 1996, Green 1994 = $ 0.1 * 0.14 = 0.1 $\n",
    "\n",
    "\n",
    "P(E) = P(A) X P(E|A) + P(B) X P(E|B)\n",
    "\n",
    "P(E) = $ 0.5 * (0.2 * 0.2) + 0.5 * (0.14 * 0.1) $\n",
    "\n",
    "P(E) = 0.027\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#P(A|E) = P(A) X P(E|A)/ P(E)\n",
    "\n",
    "def bayesestimator(prior_, likelihood_of_p, marginalization_):\n",
    "    prior = prior_\n",
    "    likelihood = likelihood_of_p\n",
    "    marginalization = marginalization_\n",
    "    myestimate = (prior * likelihood) / marginalization)\n",
    "    return myestimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chance that yellow m&m came from the 1994 bag = 74.074%\n"
     ]
    }
   ],
   "source": [
    "prior_ = 0.5\n",
    "likelihood_of_p = 0.4\n",
    "marginalization_ = 0.027\n",
    "result1 = bayesestimator(prior_, likelihood_of_p, marginalization_)\n",
    "\n",
    "print('chance that yellow m&m came from the 1994 bag = %.3f%%' % (result1 * 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Do we really need Bayes Law?\n",
    "\n",
    "An alternative approach was suggested by Peter Norvig as he reflected on Allen Downey's example...\n",
    "\n",
    "In a sense it is curious that this problem comes from a section titled by Downey as **My favorite Bayes's Theorem Problems**, as you might expect that you would need to invoke Bayes Theorem to solve it. However, the enumerative approach outlined below shows that is not strictly necessary.\n",
    "\n",
    "Yes, Bayes Theorem allows you to do less calculation but at the cost of more algebra; that is a great trade-off if you are working with pencil and paper. Enumerating the state space allows you to do less algebra at the cost of more calculation; sometimes a good trade-off if you have a computer. Using both approaches may help you to more fully understand Bayes theorem and how it works (or at least confirm that the algebra agrees with the enumerated outcome!).\n",
    "\n",
    "We can use the approach that was introduced to us in Norvig's tutorial examples of urn problems from last week. We will start by re-introducing the various functions that he developed there, though here they are replaced with slightly enhanced options (but essentially acheive the same results).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def P(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "    \n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...};\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...};\n",
    "    in both cases only with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "To tackle this particulars of this problem, we'll need to represent the probability distributions of the difference M&Ms in each bag.  We define a `ProbDist` function and then use it to create the distribution of differing colours of M&Ms contained in `bag94` and `bag96`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbDist(dict):\n",
    "    \"A Probability Distribution; an {outcome: probability} mapping.\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        # Make probabilities sum to 1.0; assert no negative probabilities\n",
    "        total = sum(self.values())\n",
    "        for outcome in self:\n",
    "            self[outcome] = self[outcome] / total\n",
    "            assert self[outcome] >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bag94 = ProbDist(brown=30, yellow=20, red=20, green=10, orange=10, tan=10)\n",
    "bag96 = ProbDist(blue=24, green=20, orange=16, yellow=14, red=13, brown=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': 0.3,\n",
       " 'yellow': 0.2,\n",
       " 'red': 0.2,\n",
       " 'green': 0.1,\n",
       " 'orange': 0.1,\n",
       " 'tan': 0.1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can check the contents of a bag (or more correctly the propotions of differing colour contents in a bag)\n",
    "bag94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We can now define `two_MM` as the joint distribution - the sample space for picking two M&Ms, one from each of the bags defined by these two distributions. The outcome `'brown - blue'` means that a brown M&M was selected from the 1994 bag and that a blue one came from the 1996 bag. There will be no entry for `blue - brown` as there were no blue M&Ms in the bags from before 1995, but for many selections we are able to find the values for various `a - b` and `b - a` outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown - blue': 0.07199999999999997,\n",
       " 'brown - green': 0.05999999999999997,\n",
       " 'brown - orange': 0.04799999999999998,\n",
       " 'brown - yellow': 0.04199999999999998,\n",
       " 'brown - red': 0.038999999999999986,\n",
       " 'brown - brown': 0.038999999999999986,\n",
       " 'yellow - blue': 0.04799999999999998,\n",
       " 'yellow - green': 0.03999999999999999,\n",
       " 'yellow - orange': 0.03199999999999999,\n",
       " 'yellow - yellow': 0.02799999999999999,\n",
       " 'yellow - red': 0.025999999999999992,\n",
       " 'yellow - brown': 0.025999999999999992,\n",
       " 'red - blue': 0.04799999999999998,\n",
       " 'red - green': 0.03999999999999999,\n",
       " 'red - orange': 0.03199999999999999,\n",
       " 'red - yellow': 0.02799999999999999,\n",
       " 'red - red': 0.025999999999999992,\n",
       " 'red - brown': 0.025999999999999992,\n",
       " 'green - blue': 0.02399999999999999,\n",
       " 'green - green': 0.019999999999999993,\n",
       " 'green - orange': 0.015999999999999993,\n",
       " 'green - yellow': 0.013999999999999995,\n",
       " 'green - red': 0.012999999999999996,\n",
       " 'green - brown': 0.012999999999999996,\n",
       " 'orange - blue': 0.02399999999999999,\n",
       " 'orange - green': 0.019999999999999993,\n",
       " 'orange - orange': 0.015999999999999993,\n",
       " 'orange - yellow': 0.013999999999999995,\n",
       " 'orange - red': 0.012999999999999996,\n",
       " 'orange - brown': 0.012999999999999996,\n",
       " 'tan - blue': 0.02399999999999999,\n",
       " 'tan - green': 0.019999999999999993,\n",
       " 'tan - orange': 0.015999999999999993,\n",
       " 'tan - yellow': 0.013999999999999995,\n",
       " 'tan - red': 0.012999999999999996,\n",
       " 'tan - brown': 0.012999999999999996}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def joint(A, B, sep=''):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "two_MM = joint(bag94, bag96, ' - ')\n",
    "two_MM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "So now we can look at the possible ways in which we result in a \"one is yellow and one is green\" as a given outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yellow - green': 0.7407407407407408, 'green - yellow': 0.25925925925925924}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yellow_and_green(outcome): return 'yellow' in outcome and 'green' in outcome\n",
    "\n",
    "such_that(yellow_and_green, two_MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we can answer the question: given that we got a yellow and a green (but don't know which comes from which bag), what is the probability that the yellow came from the 1994 bag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yellow94(outcome): return outcome.startswith('yellow')\n",
    "\n",
    "P(yellow94, such_that(yellow_and_green, two_MM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we end up with the same outcome as when we used Bayes' Rule in the previous section. Take some time (in the little exercise below) to reflect on these two approaches based on some additional examples and provide some comments on your thoughts regarding the approach/outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 2b (SUBMIT)\n",
    "\n",
    "Try some alternative outcomes - say that you were given an **orange and a red M&M**.  What is the probability that the orange M&M came from the 1994 bag?  \n",
    "\n",
    "<br>\n",
    "What about if you got a **tan and a red**?  What is the probabilty that the red came from the 1994 bag?\n",
    "\n",
    "<br>\n",
    "You should try both the 'Bayesian' and the enumerative (Norvig's) approach.  Which did you find easier?  Which seemed more intuitive to you and why?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'red - orange': 0.711111111111111, 'orange - red': 0.2888888888888889}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#orange and red m&m enumerative approach \n",
    "def orange_and_red(outcome): return 'orange' in outcome and 'red' in outcome\n",
    "\n",
    "such_that(orange_and_red, two_MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2888888888888889"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#orange and red m&m enumerative approach \n",
    "def orange94(outcome): return outcome.startswith('orange')\n",
    "\n",
    "P(orange94, such_that(orange_and_red, two_MM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algebra showing how values were gotten for orange and red m&m experiment  \n",
    "\n",
    "A = Bag 1(1994) and Bag 2(1996)\n",
    "\n",
    "B = Bag 1(1996) and Bag 2(1994) \n",
    "\n",
    "P(A) = P(B) = 0.50 \n",
    "\n",
    "Knowledge = Orange m&m from Bag 1 and Red m&m from Bag 2 \n",
    "\n",
    "P(E|A) = Orange 1994, Red 1996 = $ 0.10 * 0.13  = 0.013 $\n",
    "\n",
    "P(E|B) = Orange 1996, Red 1994 = $ 0.16 * 0.20 = 0.032 $\n",
    "\n",
    "\n",
    "P(E) = P(A) X P(E|A) + P(B) X P(E|B)\n",
    "\n",
    "P(E) = $ 0.5 * (0.10 * 0.13) + 0.5 * (0.16 * 0.20) $\n",
    "\n",
    "P(E) = 0.0225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chance that orange m&m came from the 1994 bag = 0.289%\n"
     ]
    }
   ],
   "source": [
    "#orange and red m&m bayesian approach \n",
    "#P(A|E) = P(A) X P(E|A)/ P(E)\n",
    "\n",
    "prior_ = 0.5\n",
    "likelihood_of_p = 0.013\n",
    "marginalization_ = 0.0225\n",
    "result1 = bayesestimator(prior_, likelihood_of_p, marginalization_)\n",
    "\n",
    "print('chance that orange m&m came from the 1994 bag = %.3f%%' % (result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tan - red': 1.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tan and red m&m enumerative approach \n",
    "def tan_and_red(outcome): return 'red' in outcome and 'tan' in outcome\n",
    "\n",
    "such_that(tan_and_red, two_MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tan and red m&m enumerative approach \n",
    "def red94(outcome): return outcome.startswith('red')\n",
    "\n",
    "P(red94, such_that(tan_and_red, two_MM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algebra showing how values were gotten for Tan and Red m&m experiment  \n",
    "\n",
    "A = Bag 1(1994) and Bag 2(1996)\n",
    "\n",
    "B = Bag 1(1996) and Bag 2(1994) \n",
    "\n",
    "P(A) = P(B) = 0.50 \n",
    "\n",
    "Knowledge = Tan m&m from Bag 1 and Red m&m from Bag 2 \n",
    "\n",
    "P(E|A) = Tan 1994, Red 1996 = $ 0.10 * 0.13  = 0.013 $\n",
    "\n",
    "P(E|B) = Tan 1996, Red 1994 = $ 0 * 0.20 = 0 $\n",
    "\n",
    "\n",
    "P(E) = P(A) X P(E|A) + P(B) X P(E|B)\n",
    "\n",
    "P(E) = $ 0.5 * (0.10 * 0.13) + 0.5 * (0 * 0.20) $\n",
    "\n",
    "P(E) = 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chance that red m&m came from the 1994 bag = 0.100%\n"
     ]
    }
   ],
   "source": [
    "#tan and red m&m bayesian approach \n",
    "#P(A|E) = P(A) X P(E|A)/ P(E)\n",
    "\n",
    "prior_ = 0.5\n",
    "likelihood_of_p = 0.013\n",
    "marginalization_ = 0.065\n",
    "result2 = bayesestimator(prior_, likelihood_of_p, marginalization_)\n",
    "\n",
    "print('chance that red m&m came from the 1994 bag = %.3f%%' % (result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I found the bayesian approach to be easier and much more intuitive personally as working with algebra lays it out step\n",
    "#by step and I can really see why I am getting the values I am getting \n",
    "#I imagine that the enumerative approach would be easier to follow once my understanding of python increases "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
